目前来说，GPU贵，功耗高，运行效率比FPGA高，易使用。FPGA功耗，单颗性能是低的，单颗FPGA的硬件设计挑战没有GPU大，但是总体性价比和效率不占优。

另外一个问题是，FPGA的大规模开发难度偏高，从业人员少。

FPGA在深度学习的应用场景，存在的价值在于其灵活性。FPGA犹如乐高，其灵活性，根据实际应用的需求，构建我所需要的硬件组件。FPGA可以查找表和触发器子单元，组合成任意运算单元，而深度学习的参数都是数学模型，需要RTL级的优化（register transfer level，指的是用寄存器这一级别的描述方式来描述电路的数据流方式），FPGA正适合这一点。

缺点也在灵活性：具备灵活性就意味着失去专门性，其功耗性能比，可变布线资源、多余的逻辑资源，其实都是浪费。

GPU的一个缺点是，他的组件模块是乘法器、加法器。虽然深度学习的参数都是数学模型，需要RTL级的优化，但是GPU的硬件资源是以乘法器、加法器这样量级的硬件单元组成的。如果GPU的预先配置与使用者的模型相差甚远。例如：加法器配置15个，乘法器配置15个。但实际使用的时候，乘法器使用量是15个，但是加法器只需要2个。这就浪费了13个加法器的资源。而FPGA是以查找表和触发器子单元，组合成任意运算单元。



[GPU](http://www.elecfans.com/tags/gpu/)：又称显示核心、视觉处理器、显示芯片，是一种专门在个人电脑、工作站、游戏机和一些移动设备（如平板电脑、智能手机等）上做图像运算工作的微处理器。其用途是将计算机系统所需要的显示信息进行转换驱动，并向显示器提供行扫描信号，控制显示器的正确显示，是连接显示器和个人电脑主板的重要元件，也是“人机对话”的重要设备之一。

[FPGA](http://www.elecfans.com/tags/fpga/)：即现场可编程门阵列，它是在PAL、GAL、[CPLD](http://www.elecfans.com/tags/cpld/)等可编程器件的基础上进一步发展的产物。作为专用集成电路（[ASIC](http://www.elecfans.com/tags/asic/)）领域中的一种半定制电路而出现的芯片，既解决了定制电路的不足，又克服了原有可编程器件门电路数有限的缺点。系统设计师可以根据需要通过可编辑的连接把FPGA内部的逻辑块连接起来，就好像一个电路试验板被放在了一个芯片里。

ASIC：即专用集成电路，是指应特定用户要求和特定电子系统的需要而设计、制造的集成电路。目前用CPLD（复杂可编程逻辑器件）和FPGA（现场可编程逻辑阵列）来进行ASIC设计是最为流行的方式之一，它们的共性是都具有用户现场可编程特性，都支持边界扫描技术，但两者在集成度、速度以及编程方式上具有各自的特点。

ASIC的特点是面向特定用户的需求，品种多、批量少，要求设计和生产周期短，它作为集成电路技术与特定用户的整机或系统技术紧密结合的产物，与通用集成电路相比具有体积更小、重量更轻、功耗更低、可靠性提高、性能提高、保密性增强、成本降低等优点。

TPU（[Te](http://www.elecfans.com/tags/te/)nsor Processing Unit）：是谷歌研发的一种神经网络训练的处理器，主要用于深度学习、AI运算。TPU具有像GPU和[CPU](http://www.elecfans.com/tags/cpu/)一样的编程，以及一套CISC指令集。作为[机器学习](http://www.elecfans.com/tags/机器学习/)处理器，不仅仅支持某一种神经网络，还支持卷积神经网络、LSTM、全连接网络等多种。TPU采用低精度（8位）计算，以降低每步操作使用的[晶体管](http://www.elecfans.com/tags/晶体管/)数量。

虽然降低精度对于深度学习的准确度影响很小，但却可以大幅降低功耗、加快运算速度。同时，TPU使用了脉动阵列的设计，用来优化矩阵乘法与卷积运算，减少I/O操作。此外，TPU还采用了更大的片上内存，以此减少对[DRAM](http://www.elecfans.com/tags/dram/)的访问，从而更大程度地提升性能。





通用性和最优化无法两全：

CPU 和 GPU 的架构都有非常沉重的历史包袱，体现在：
它们都有很强的通用性，不能仅仅只针对某个领域做优化
它们都有很强的兼容性，过去编写的程序必须能够运行
它们都有稳定而庞大的程序员队伍，



如果扔掉这些包袱，设计全新的架构，就可以做到：

仅仅针对某个领域做优化
不考虑对过去软件的兼容
用全新的方式对其编程，不拘泥于之前的思维定势这样设计出的架构，对其目标领域，性能指标会大幅度超越 CPU 和 GPU 这类通用架构。



寻找新架构：FPGA：开辟新道路

FPGA 是什么？如果说 CPU 和 GPU 是在架构级别做到“通用”的话，FPGA 就是在更低一级的电路级做到了“通用”。通过硬件描述语言对[ FPGA](https://www.eefocus.com/tag/FPGA) 编程后，它可以模拟任何一种芯片的架构，包括 CPU 和 GPU 的架构，通俗地说，FPGA 是一种可编程的“万能芯片”。它非常适合探索性的、小批量的产品。

很多的 FPGA 方案，实现了比 GPU 更好的速度、功耗或成本的指标。但是，FPGA 依然无法摆脱“通用就无法最优”这一规律的制约。

为什么FPGA体现出了优势？

算法的影响 >> 硬件架构的影响 >> 电路的影响

CPU/GPU：硬件架构级的通用

FPGA：电路级的通用

ASIC/TPU：专用



同柯洁对阵的 AlphaGo，采用了 Google 自研的第二代 TPU（Tensor Processing Unit）

TPU 的特点是：
仅仅针对线性代数做优化
不兼容 CPU 或 GPU 的程序
用全新的方式对其编程用 ASIC 而非 FPGA 的方式来实现

为什么TPU高效？

深度学习所使用算法，绝大多数可以被映射为底层的线性代数运算。TPU（Tensor Processing Unit）中的 Tensor，就是线性代数中的基本数据类型。线性代数运算有两大特点：Tensor 的流动非常规整且可预期；计算密度很高，即每个数据都会历经非常多次的计算。这两大特点使得线性代数运算特别适合做硬件加速。

因此，专门对线性代数作优化的TPU十分适合加速深度学习。

ASIC的困难与风险：ASIC 效能远超 FPGA，但仍然有很多人不敢选择 ASIC，为什么？自己做 ASIC 的风险太大：周期长，投入多，门槛高。一旦芯片做错，就和石头无异，落个血本无归。